{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iris.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUdrpCpN_3iw",
        "outputId": "af9208c9-512e-427f-9f6e-b6a07315ff30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "iris = load_iris()\n",
        "X = preprocessing.scale(iris['data'])\n",
        "Y = to_categorical(iris['target'])\n",
        "\n",
        "#training data and test data\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "#model\n",
        "model = Sequential()\n",
        "model.add(Dense(6, input_dim=4, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "#fitting the model\n",
        "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=500, batch_size=10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "12/12 [==============================] - 0s 11ms/step - loss: 1.5916 - accuracy: 0.2917 - val_loss: 1.9237 - val_accuracy: 0.2000\n",
            "Epoch 2/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.5314 - accuracy: 0.3083 - val_loss: 1.8430 - val_accuracy: 0.2000\n",
            "Epoch 3/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 1.4763 - accuracy: 0.3167 - val_loss: 1.7643 - val_accuracy: 0.2000\n",
            "Epoch 4/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.4241 - accuracy: 0.3167 - val_loss: 1.6891 - val_accuracy: 0.1667\n",
            "Epoch 5/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.3723 - accuracy: 0.3167 - val_loss: 1.6215 - val_accuracy: 0.1667\n",
            "Epoch 6/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.3221 - accuracy: 0.3417 - val_loss: 1.5603 - val_accuracy: 0.1667\n",
            "Epoch 7/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2796 - accuracy: 0.3667 - val_loss: 1.4968 - val_accuracy: 0.1667\n",
            "Epoch 8/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.2346 - accuracy: 0.3667 - val_loss: 1.4404 - val_accuracy: 0.1667\n",
            "Epoch 9/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1939 - accuracy: 0.4000 - val_loss: 1.3873 - val_accuracy: 0.3000\n",
            "Epoch 10/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1562 - accuracy: 0.4000 - val_loss: 1.3381 - val_accuracy: 0.3333\n",
            "Epoch 11/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.1195 - accuracy: 0.4083 - val_loss: 1.2911 - val_accuracy: 0.3333\n",
            "Epoch 12/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0850 - accuracy: 0.4667 - val_loss: 1.2501 - val_accuracy: 0.3333\n",
            "Epoch 13/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0530 - accuracy: 0.4833 - val_loss: 1.2074 - val_accuracy: 0.3667\n",
            "Epoch 14/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 1.0219 - accuracy: 0.4917 - val_loss: 1.1663 - val_accuracy: 0.4000\n",
            "Epoch 15/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9922 - accuracy: 0.4917 - val_loss: 1.1300 - val_accuracy: 0.4667\n",
            "Epoch 16/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9663 - accuracy: 0.5167 - val_loss: 1.0960 - val_accuracy: 0.5000\n",
            "Epoch 17/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.9424 - accuracy: 0.5500 - val_loss: 1.0646 - val_accuracy: 0.5000\n",
            "Epoch 18/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.9197 - accuracy: 0.5583 - val_loss: 1.0359 - val_accuracy: 0.5000\n",
            "Epoch 19/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8992 - accuracy: 0.5750 - val_loss: 1.0088 - val_accuracy: 0.5000\n",
            "Epoch 20/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8798 - accuracy: 0.5917 - val_loss: 0.9849 - val_accuracy: 0.5000\n",
            "Epoch 21/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8627 - accuracy: 0.6000 - val_loss: 0.9621 - val_accuracy: 0.5333\n",
            "Epoch 22/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8470 - accuracy: 0.6333 - val_loss: 0.9413 - val_accuracy: 0.6667\n",
            "Epoch 23/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8322 - accuracy: 0.6583 - val_loss: 0.9211 - val_accuracy: 0.6333\n",
            "Epoch 24/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.8180 - accuracy: 0.6667 - val_loss: 0.9019 - val_accuracy: 0.6333\n",
            "Epoch 25/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.8047 - accuracy: 0.6833 - val_loss: 0.8840 - val_accuracy: 0.6333\n",
            "Epoch 26/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7927 - accuracy: 0.7083 - val_loss: 0.8674 - val_accuracy: 0.6667\n",
            "Epoch 27/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7810 - accuracy: 0.7167 - val_loss: 0.8530 - val_accuracy: 0.6667\n",
            "Epoch 28/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7704 - accuracy: 0.7167 - val_loss: 0.8381 - val_accuracy: 0.6667\n",
            "Epoch 29/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7593 - accuracy: 0.7250 - val_loss: 0.8252 - val_accuracy: 0.6667\n",
            "Epoch 30/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7497 - accuracy: 0.7250 - val_loss: 0.8115 - val_accuracy: 0.6667\n",
            "Epoch 31/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7396 - accuracy: 0.7333 - val_loss: 0.7988 - val_accuracy: 0.6667\n",
            "Epoch 32/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7300 - accuracy: 0.7583 - val_loss: 0.7871 - val_accuracy: 0.6667\n",
            "Epoch 33/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7211 - accuracy: 0.7667 - val_loss: 0.7747 - val_accuracy: 0.7000\n",
            "Epoch 34/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.7121 - accuracy: 0.7750 - val_loss: 0.7638 - val_accuracy: 0.7333\n",
            "Epoch 35/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.7038 - accuracy: 0.8000 - val_loss: 0.7528 - val_accuracy: 0.7667\n",
            "Epoch 36/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6954 - accuracy: 0.8083 - val_loss: 0.7419 - val_accuracy: 0.7667\n",
            "Epoch 37/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6876 - accuracy: 0.8083 - val_loss: 0.7318 - val_accuracy: 0.8000\n",
            "Epoch 38/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.8083 - val_loss: 0.7222 - val_accuracy: 0.8333\n",
            "Epoch 39/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6715 - accuracy: 0.8083 - val_loss: 0.7125 - val_accuracy: 0.8667\n",
            "Epoch 40/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.8083 - val_loss: 0.7036 - val_accuracy: 0.8667\n",
            "Epoch 41/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6566 - accuracy: 0.8167 - val_loss: 0.6942 - val_accuracy: 0.8667\n",
            "Epoch 42/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.8250 - val_loss: 0.6844 - val_accuracy: 0.8667\n",
            "Epoch 43/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.8333 - val_loss: 0.6762 - val_accuracy: 0.8667\n",
            "Epoch 44/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.8333 - val_loss: 0.6677 - val_accuracy: 0.8667\n",
            "Epoch 45/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.8333 - val_loss: 0.6592 - val_accuracy: 0.8667\n",
            "Epoch 46/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.8417 - val_loss: 0.6510 - val_accuracy: 0.8667\n",
            "Epoch 47/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.8417 - val_loss: 0.6425 - val_accuracy: 0.9000\n",
            "Epoch 48/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6088 - accuracy: 0.8417 - val_loss: 0.6351 - val_accuracy: 0.9000\n",
            "Epoch 49/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.6027 - accuracy: 0.8417 - val_loss: 0.6278 - val_accuracy: 0.9000\n",
            "Epoch 50/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5973 - accuracy: 0.8417 - val_loss: 0.6201 - val_accuracy: 0.9000\n",
            "Epoch 51/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5909 - accuracy: 0.8500 - val_loss: 0.6134 - val_accuracy: 0.9000\n",
            "Epoch 52/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.8500 - val_loss: 0.6065 - val_accuracy: 0.9333\n",
            "Epoch 53/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5796 - accuracy: 0.8500 - val_loss: 0.5996 - val_accuracy: 0.9333\n",
            "Epoch 54/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5734 - accuracy: 0.8500 - val_loss: 0.5923 - val_accuracy: 0.9333\n",
            "Epoch 55/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5680 - accuracy: 0.8500 - val_loss: 0.5852 - val_accuracy: 0.9333\n",
            "Epoch 56/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.8583 - val_loss: 0.5789 - val_accuracy: 0.9333\n",
            "Epoch 57/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5573 - accuracy: 0.8667 - val_loss: 0.5723 - val_accuracy: 0.9333\n",
            "Epoch 58/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.8750 - val_loss: 0.5660 - val_accuracy: 0.9333\n",
            "Epoch 59/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5465 - accuracy: 0.8750 - val_loss: 0.5601 - val_accuracy: 0.9333\n",
            "Epoch 60/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.8750 - val_loss: 0.5539 - val_accuracy: 0.9333\n",
            "Epoch 61/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5362 - accuracy: 0.8750 - val_loss: 0.5479 - val_accuracy: 0.9333\n",
            "Epoch 62/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.8833 - val_loss: 0.5422 - val_accuracy: 0.9333\n",
            "Epoch 63/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.5262 - accuracy: 0.8833 - val_loss: 0.5364 - val_accuracy: 0.9333\n",
            "Epoch 64/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.8833 - val_loss: 0.5304 - val_accuracy: 0.9333\n",
            "Epoch 65/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5161 - accuracy: 0.8833 - val_loss: 0.5247 - val_accuracy: 0.9333\n",
            "Epoch 66/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.8917 - val_loss: 0.5192 - val_accuracy: 0.9333\n",
            "Epoch 67/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.8917 - val_loss: 0.5137 - val_accuracy: 0.9333\n",
            "Epoch 68/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.8917 - val_loss: 0.5083 - val_accuracy: 0.9333\n",
            "Epoch 69/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4974 - accuracy: 0.8917 - val_loss: 0.5031 - val_accuracy: 0.9333\n",
            "Epoch 70/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.9000 - val_loss: 0.4976 - val_accuracy: 0.9333\n",
            "Epoch 71/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.9083 - val_loss: 0.4925 - val_accuracy: 0.9333\n",
            "Epoch 72/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.9167 - val_loss: 0.4871 - val_accuracy: 0.9333\n",
            "Epoch 73/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.9167 - val_loss: 0.4821 - val_accuracy: 0.9333\n",
            "Epoch 74/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.9167 - val_loss: 0.4773 - val_accuracy: 0.9333\n",
            "Epoch 75/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4696 - accuracy: 0.9167 - val_loss: 0.4722 - val_accuracy: 0.9333\n",
            "Epoch 76/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4650 - accuracy: 0.9167 - val_loss: 0.4674 - val_accuracy: 0.9333\n",
            "Epoch 77/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4607 - accuracy: 0.9167 - val_loss: 0.4625 - val_accuracy: 0.9333\n",
            "Epoch 78/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.9167 - val_loss: 0.4578 - val_accuracy: 0.9333\n",
            "Epoch 79/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4519 - accuracy: 0.9250 - val_loss: 0.4532 - val_accuracy: 0.9333\n",
            "Epoch 80/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4472 - accuracy: 0.9250 - val_loss: 0.4486 - val_accuracy: 0.9333\n",
            "Epoch 81/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4439 - accuracy: 0.9250 - val_loss: 0.4440 - val_accuracy: 0.9333\n",
            "Epoch 82/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4389 - accuracy: 0.9250 - val_loss: 0.4398 - val_accuracy: 0.9333\n",
            "Epoch 83/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4346 - accuracy: 0.9250 - val_loss: 0.4354 - val_accuracy: 0.9333\n",
            "Epoch 84/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.9167 - val_loss: 0.4310 - val_accuracy: 0.9333\n",
            "Epoch 85/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.9250 - val_loss: 0.4267 - val_accuracy: 0.9333\n",
            "Epoch 86/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4223 - accuracy: 0.9250 - val_loss: 0.4223 - val_accuracy: 0.9333\n",
            "Epoch 87/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4182 - accuracy: 0.9250 - val_loss: 0.4181 - val_accuracy: 0.9333\n",
            "Epoch 88/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4146 - accuracy: 0.9333 - val_loss: 0.4140 - val_accuracy: 0.9333\n",
            "Epoch 89/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4107 - accuracy: 0.9333 - val_loss: 0.4097 - val_accuracy: 0.9667\n",
            "Epoch 90/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.9333 - val_loss: 0.4058 - val_accuracy: 0.9667\n",
            "Epoch 91/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.9333 - val_loss: 0.4016 - val_accuracy: 0.9667\n",
            "Epoch 92/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3993 - accuracy: 0.9250 - val_loss: 0.3979 - val_accuracy: 0.9667\n",
            "Epoch 93/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.9250 - val_loss: 0.3939 - val_accuracy: 0.9667\n",
            "Epoch 94/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3916 - accuracy: 0.9250 - val_loss: 0.3898 - val_accuracy: 0.9667\n",
            "Epoch 95/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3879 - accuracy: 0.9250 - val_loss: 0.3862 - val_accuracy: 0.9667\n",
            "Epoch 96/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.9250 - val_loss: 0.3822 - val_accuracy: 0.9667\n",
            "Epoch 97/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3805 - accuracy: 0.9250 - val_loss: 0.3785 - val_accuracy: 0.9667\n",
            "Epoch 98/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.9250 - val_loss: 0.3747 - val_accuracy: 0.9667\n",
            "Epoch 99/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3737 - accuracy: 0.9250 - val_loss: 0.3711 - val_accuracy: 0.9667\n",
            "Epoch 100/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.9250 - val_loss: 0.3675 - val_accuracy: 0.9667\n",
            "Epoch 101/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3663 - accuracy: 0.9250 - val_loss: 0.3640 - val_accuracy: 0.9667\n",
            "Epoch 102/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3628 - accuracy: 0.9250 - val_loss: 0.3602 - val_accuracy: 0.9667\n",
            "Epoch 103/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3594 - accuracy: 0.9250 - val_loss: 0.3569 - val_accuracy: 0.9667\n",
            "Epoch 104/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.9333 - val_loss: 0.3534 - val_accuracy: 0.9667\n",
            "Epoch 105/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.9333 - val_loss: 0.3499 - val_accuracy: 0.9667\n",
            "Epoch 106/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.9333 - val_loss: 0.3468 - val_accuracy: 0.9667\n",
            "Epoch 107/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3454 - accuracy: 0.9333 - val_loss: 0.3434 - val_accuracy: 0.9667\n",
            "Epoch 108/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.9333 - val_loss: 0.3400 - val_accuracy: 0.9667\n",
            "Epoch 109/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3388 - accuracy: 0.9333 - val_loss: 0.3367 - val_accuracy: 0.9667\n",
            "Epoch 110/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3357 - accuracy: 0.9333 - val_loss: 0.3334 - val_accuracy: 0.9667\n",
            "Epoch 111/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.9333 - val_loss: 0.3303 - val_accuracy: 0.9667\n",
            "Epoch 112/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.9333 - val_loss: 0.3274 - val_accuracy: 0.9667\n",
            "Epoch 113/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.9333 - val_loss: 0.3243 - val_accuracy: 0.9667\n",
            "Epoch 114/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3228 - accuracy: 0.9333 - val_loss: 0.3211 - val_accuracy: 0.9667\n",
            "Epoch 115/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.9333 - val_loss: 0.3180 - val_accuracy: 0.9667\n",
            "Epoch 116/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3169 - accuracy: 0.9333 - val_loss: 0.3152 - val_accuracy: 0.9667\n",
            "Epoch 117/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 0.9417 - val_loss: 0.3121 - val_accuracy: 0.9667\n",
            "Epoch 118/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.9417 - val_loss: 0.3092 - val_accuracy: 0.9667\n",
            "Epoch 119/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.9417 - val_loss: 0.3063 - val_accuracy: 0.9667\n",
            "Epoch 120/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.3049 - accuracy: 0.9417 - val_loss: 0.3033 - val_accuracy: 0.9667\n",
            "Epoch 121/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.9417 - val_loss: 0.3007 - val_accuracy: 0.9667\n",
            "Epoch 122/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2990 - accuracy: 0.9500 - val_loss: 0.2979 - val_accuracy: 0.9667\n",
            "Epoch 123/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2962 - accuracy: 0.9500 - val_loss: 0.2951 - val_accuracy: 0.9667\n",
            "Epoch 124/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2938 - accuracy: 0.9500 - val_loss: 0.2926 - val_accuracy: 0.9667\n",
            "Epoch 125/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2907 - accuracy: 0.9500 - val_loss: 0.2897 - val_accuracy: 0.9667\n",
            "Epoch 126/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.9500 - val_loss: 0.2869 - val_accuracy: 0.9667\n",
            "Epoch 127/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2852 - accuracy: 0.9583 - val_loss: 0.2844 - val_accuracy: 0.9667\n",
            "Epoch 128/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.9583 - val_loss: 0.2821 - val_accuracy: 0.9667\n",
            "Epoch 129/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2800 - accuracy: 0.9583 - val_loss: 0.2793 - val_accuracy: 0.9667\n",
            "Epoch 130/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.9583 - val_loss: 0.2767 - val_accuracy: 0.9667\n",
            "Epoch 131/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2751 - accuracy: 0.9583 - val_loss: 0.2742 - val_accuracy: 0.9667\n",
            "Epoch 132/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.9583 - val_loss: 0.2719 - val_accuracy: 0.9667\n",
            "Epoch 133/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2699 - accuracy: 0.9583 - val_loss: 0.2692 - val_accuracy: 0.9667\n",
            "Epoch 134/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2672 - accuracy: 0.9583 - val_loss: 0.2669 - val_accuracy: 0.9667\n",
            "Epoch 135/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2650 - accuracy: 0.9583 - val_loss: 0.2646 - val_accuracy: 0.9667\n",
            "Epoch 136/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2625 - accuracy: 0.9583 - val_loss: 0.2623 - val_accuracy: 0.9667\n",
            "Epoch 137/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2602 - accuracy: 0.9583 - val_loss: 0.2600 - val_accuracy: 0.9667\n",
            "Epoch 138/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2577 - accuracy: 0.9583 - val_loss: 0.2576 - val_accuracy: 0.9667\n",
            "Epoch 139/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2555 - accuracy: 0.9583 - val_loss: 0.2555 - val_accuracy: 0.9667\n",
            "Epoch 140/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2531 - accuracy: 0.9583 - val_loss: 0.2531 - val_accuracy: 0.9667\n",
            "Epoch 141/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2510 - accuracy: 0.9583 - val_loss: 0.2507 - val_accuracy: 0.9667\n",
            "Epoch 142/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2488 - accuracy: 0.9583 - val_loss: 0.2487 - val_accuracy: 0.9667\n",
            "Epoch 143/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2465 - accuracy: 0.9583 - val_loss: 0.2466 - val_accuracy: 0.9667\n",
            "Epoch 144/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2441 - accuracy: 0.9583 - val_loss: 0.2445 - val_accuracy: 0.9667\n",
            "Epoch 145/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2420 - accuracy: 0.9583 - val_loss: 0.2424 - val_accuracy: 0.9667\n",
            "Epoch 146/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.2397 - accuracy: 0.9583 - val_loss: 0.2403 - val_accuracy: 0.9667\n",
            "Epoch 147/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2380 - accuracy: 0.9667 - val_loss: 0.2385 - val_accuracy: 0.9667\n",
            "Epoch 148/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2357 - accuracy: 0.9750 - val_loss: 0.2363 - val_accuracy: 0.9667\n",
            "Epoch 149/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2336 - accuracy: 0.9750 - val_loss: 0.2344 - val_accuracy: 0.9667\n",
            "Epoch 150/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2315 - accuracy: 0.9750 - val_loss: 0.2324 - val_accuracy: 0.9667\n",
            "Epoch 151/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2296 - accuracy: 0.9750 - val_loss: 0.2306 - val_accuracy: 0.9667\n",
            "Epoch 152/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2275 - accuracy: 0.9750 - val_loss: 0.2287 - val_accuracy: 0.9667\n",
            "Epoch 153/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2256 - accuracy: 0.9750 - val_loss: 0.2267 - val_accuracy: 0.9667\n",
            "Epoch 154/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2237 - accuracy: 0.9750 - val_loss: 0.2249 - val_accuracy: 0.9667\n",
            "Epoch 155/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2217 - accuracy: 0.9750 - val_loss: 0.2231 - val_accuracy: 0.9667\n",
            "Epoch 156/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2200 - accuracy: 0.9750 - val_loss: 0.2213 - val_accuracy: 0.9667\n",
            "Epoch 157/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2183 - accuracy: 0.9750 - val_loss: 0.2193 - val_accuracy: 0.9667\n",
            "Epoch 158/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2161 - accuracy: 0.9750 - val_loss: 0.2177 - val_accuracy: 0.9667\n",
            "Epoch 159/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2144 - accuracy: 0.9750 - val_loss: 0.2161 - val_accuracy: 0.9667\n",
            "Epoch 160/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2127 - accuracy: 0.9750 - val_loss: 0.2144 - val_accuracy: 0.9667\n",
            "Epoch 161/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2107 - accuracy: 0.9750 - val_loss: 0.2125 - val_accuracy: 0.9667\n",
            "Epoch 162/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2091 - accuracy: 0.9750 - val_loss: 0.2110 - val_accuracy: 0.9667\n",
            "Epoch 163/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2072 - accuracy: 0.9750 - val_loss: 0.2093 - val_accuracy: 0.9667\n",
            "Epoch 164/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2058 - accuracy: 0.9750 - val_loss: 0.2076 - val_accuracy: 0.9667\n",
            "Epoch 165/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2039 - accuracy: 0.9750 - val_loss: 0.2059 - val_accuracy: 0.9667\n",
            "Epoch 166/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.2027 - accuracy: 0.9750 - val_loss: 0.2046 - val_accuracy: 0.9667\n",
            "Epoch 167/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.2009 - accuracy: 0.9750 - val_loss: 0.2027 - val_accuracy: 0.9667\n",
            "Epoch 168/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1990 - accuracy: 0.9750 - val_loss: 0.2013 - val_accuracy: 0.9667\n",
            "Epoch 169/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1974 - accuracy: 0.9750 - val_loss: 0.1998 - val_accuracy: 0.9667\n",
            "Epoch 170/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1957 - accuracy: 0.9750 - val_loss: 0.1984 - val_accuracy: 0.9667\n",
            "Epoch 171/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1941 - accuracy: 0.9750 - val_loss: 0.1968 - val_accuracy: 0.9667\n",
            "Epoch 172/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1926 - accuracy: 0.9750 - val_loss: 0.1953 - val_accuracy: 0.9667\n",
            "Epoch 173/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1916 - accuracy: 0.9750 - val_loss: 0.1938 - val_accuracy: 0.9667\n",
            "Epoch 174/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1901 - accuracy: 0.9750 - val_loss: 0.1928 - val_accuracy: 0.9667\n",
            "Epoch 175/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1883 - accuracy: 0.9750 - val_loss: 0.1910 - val_accuracy: 0.9667\n",
            "Epoch 176/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1867 - accuracy: 0.9750 - val_loss: 0.1896 - val_accuracy: 0.9667\n",
            "Epoch 177/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.9750 - val_loss: 0.1887 - val_accuracy: 0.9667\n",
            "Epoch 178/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1835 - accuracy: 0.9750 - val_loss: 0.1871 - val_accuracy: 0.9667\n",
            "Epoch 179/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1821 - accuracy: 0.9750 - val_loss: 0.1856 - val_accuracy: 0.9667\n",
            "Epoch 180/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9750 - val_loss: 0.1844 - val_accuracy: 0.9667\n",
            "Epoch 181/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1794 - accuracy: 0.9750 - val_loss: 0.1829 - val_accuracy: 0.9667\n",
            "Epoch 182/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1781 - accuracy: 0.9750 - val_loss: 0.1818 - val_accuracy: 0.9667\n",
            "Epoch 183/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1770 - accuracy: 0.9750 - val_loss: 0.1804 - val_accuracy: 0.9667\n",
            "Epoch 184/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1754 - accuracy: 0.9750 - val_loss: 0.1790 - val_accuracy: 0.9667\n",
            "Epoch 185/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1741 - accuracy: 0.9750 - val_loss: 0.1778 - val_accuracy: 0.9667\n",
            "Epoch 186/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1734 - accuracy: 0.9750 - val_loss: 0.1772 - val_accuracy: 0.9667\n",
            "Epoch 187/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1715 - accuracy: 0.9750 - val_loss: 0.1756 - val_accuracy: 0.9667\n",
            "Epoch 188/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1706 - accuracy: 0.9750 - val_loss: 0.1741 - val_accuracy: 0.9667\n",
            "Epoch 189/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1690 - accuracy: 0.9750 - val_loss: 0.1732 - val_accuracy: 0.9667\n",
            "Epoch 190/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9750 - val_loss: 0.1720 - val_accuracy: 0.9667\n",
            "Epoch 191/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1666 - accuracy: 0.9750 - val_loss: 0.1709 - val_accuracy: 0.9667\n",
            "Epoch 192/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1652 - accuracy: 0.9750 - val_loss: 0.1700 - val_accuracy: 0.9667\n",
            "Epoch 193/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1641 - accuracy: 0.9750 - val_loss: 0.1691 - val_accuracy: 0.9667\n",
            "Epoch 194/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1628 - accuracy: 0.9750 - val_loss: 0.1681 - val_accuracy: 0.9667\n",
            "Epoch 195/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1625 - accuracy: 0.9750 - val_loss: 0.1661 - val_accuracy: 0.9667\n",
            "Epoch 196/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1607 - accuracy: 0.9750 - val_loss: 0.1656 - val_accuracy: 0.9667\n",
            "Epoch 197/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1593 - accuracy: 0.9750 - val_loss: 0.1646 - val_accuracy: 0.9667\n",
            "Epoch 198/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1585 - accuracy: 0.9750 - val_loss: 0.1631 - val_accuracy: 0.9667\n",
            "Epoch 199/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1571 - accuracy: 0.9750 - val_loss: 0.1625 - val_accuracy: 0.9667\n",
            "Epoch 200/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1561 - accuracy: 0.9750 - val_loss: 0.1614 - val_accuracy: 0.9667\n",
            "Epoch 201/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1550 - accuracy: 0.9750 - val_loss: 0.1600 - val_accuracy: 0.9667\n",
            "Epoch 202/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1539 - accuracy: 0.9750 - val_loss: 0.1593 - val_accuracy: 0.9667\n",
            "Epoch 203/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1528 - accuracy: 0.9750 - val_loss: 0.1584 - val_accuracy: 0.9667\n",
            "Epoch 204/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1519 - accuracy: 0.9750 - val_loss: 0.1579 - val_accuracy: 0.9667\n",
            "Epoch 205/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1507 - accuracy: 0.9750 - val_loss: 0.1565 - val_accuracy: 0.9667\n",
            "Epoch 206/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1500 - accuracy: 0.9750 - val_loss: 0.1558 - val_accuracy: 0.9667\n",
            "Epoch 207/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9750 - val_loss: 0.1545 - val_accuracy: 0.9667\n",
            "Epoch 208/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1476 - accuracy: 0.9750 - val_loss: 0.1537 - val_accuracy: 0.9667\n",
            "Epoch 209/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1467 - accuracy: 0.9750 - val_loss: 0.1530 - val_accuracy: 0.9667\n",
            "Epoch 210/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1458 - accuracy: 0.9750 - val_loss: 0.1520 - val_accuracy: 0.9667\n",
            "Epoch 211/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1448 - accuracy: 0.9750 - val_loss: 0.1507 - val_accuracy: 0.9667\n",
            "Epoch 212/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1438 - accuracy: 0.9750 - val_loss: 0.1502 - val_accuracy: 0.9667\n",
            "Epoch 213/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9750 - val_loss: 0.1492 - val_accuracy: 0.9667\n",
            "Epoch 214/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1421 - accuracy: 0.9750 - val_loss: 0.1488 - val_accuracy: 0.9667\n",
            "Epoch 215/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.9750 - val_loss: 0.1476 - val_accuracy: 0.9667\n",
            "Epoch 216/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1401 - accuracy: 0.9750 - val_loss: 0.1470 - val_accuracy: 0.9667\n",
            "Epoch 217/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1393 - accuracy: 0.9750 - val_loss: 0.1463 - val_accuracy: 0.9667\n",
            "Epoch 218/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1385 - accuracy: 0.9750 - val_loss: 0.1453 - val_accuracy: 0.9667\n",
            "Epoch 219/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1375 - accuracy: 0.9750 - val_loss: 0.1443 - val_accuracy: 0.9667\n",
            "Epoch 220/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1368 - accuracy: 0.9750 - val_loss: 0.1433 - val_accuracy: 0.9667\n",
            "Epoch 221/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1359 - accuracy: 0.9750 - val_loss: 0.1432 - val_accuracy: 0.9667\n",
            "Epoch 222/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1349 - accuracy: 0.9750 - val_loss: 0.1424 - val_accuracy: 0.9667\n",
            "Epoch 223/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1343 - accuracy: 0.9750 - val_loss: 0.1414 - val_accuracy: 0.9667\n",
            "Epoch 224/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1331 - accuracy: 0.9750 - val_loss: 0.1408 - val_accuracy: 0.9667\n",
            "Epoch 225/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1325 - accuracy: 0.9750 - val_loss: 0.1401 - val_accuracy: 0.9667\n",
            "Epoch 226/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1322 - accuracy: 0.9750 - val_loss: 0.1389 - val_accuracy: 0.9667\n",
            "Epoch 227/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9750 - val_loss: 0.1390 - val_accuracy: 0.9667\n",
            "Epoch 228/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9750 - val_loss: 0.1381 - val_accuracy: 0.9667\n",
            "Epoch 229/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9750 - val_loss: 0.1368 - val_accuracy: 0.9667\n",
            "Epoch 230/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1286 - accuracy: 0.9750 - val_loss: 0.1364 - val_accuracy: 0.9667\n",
            "Epoch 231/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1278 - accuracy: 0.9750 - val_loss: 0.1359 - val_accuracy: 0.9667\n",
            "Epoch 232/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1271 - accuracy: 0.9750 - val_loss: 0.1348 - val_accuracy: 0.9667\n",
            "Epoch 233/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1262 - accuracy: 0.9750 - val_loss: 0.1344 - val_accuracy: 0.9667\n",
            "Epoch 234/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1256 - accuracy: 0.9750 - val_loss: 0.1340 - val_accuracy: 0.9667\n",
            "Epoch 235/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1249 - accuracy: 0.9750 - val_loss: 0.1329 - val_accuracy: 0.9667\n",
            "Epoch 236/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1241 - accuracy: 0.9833 - val_loss: 0.1322 - val_accuracy: 0.9667\n",
            "Epoch 237/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9750 - val_loss: 0.1318 - val_accuracy: 0.9667\n",
            "Epoch 238/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1226 - accuracy: 0.9750 - val_loss: 0.1313 - val_accuracy: 0.9667\n",
            "Epoch 239/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1220 - accuracy: 0.9750 - val_loss: 0.1305 - val_accuracy: 0.9667\n",
            "Epoch 240/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1217 - accuracy: 0.9750 - val_loss: 0.1305 - val_accuracy: 0.9667\n",
            "Epoch 241/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1208 - accuracy: 0.9833 - val_loss: 0.1292 - val_accuracy: 0.9667\n",
            "Epoch 242/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1199 - accuracy: 0.9750 - val_loss: 0.1287 - val_accuracy: 0.9667\n",
            "Epoch 243/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.9750 - val_loss: 0.1284 - val_accuracy: 0.9667\n",
            "Epoch 244/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1186 - accuracy: 0.9750 - val_loss: 0.1279 - val_accuracy: 0.9667\n",
            "Epoch 245/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1180 - accuracy: 0.9750 - val_loss: 0.1274 - val_accuracy: 0.9667\n",
            "Epoch 246/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1173 - accuracy: 0.9750 - val_loss: 0.1264 - val_accuracy: 0.9667\n",
            "Epoch 247/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1167 - accuracy: 0.9833 - val_loss: 0.1260 - val_accuracy: 0.9667\n",
            "Epoch 248/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1162 - accuracy: 0.9833 - val_loss: 0.1256 - val_accuracy: 0.9667\n",
            "Epoch 249/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1154 - accuracy: 0.9750 - val_loss: 0.1247 - val_accuracy: 0.9667\n",
            "Epoch 250/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1148 - accuracy: 0.9833 - val_loss: 0.1239 - val_accuracy: 0.9667\n",
            "Epoch 251/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1143 - accuracy: 0.9833 - val_loss: 0.1236 - val_accuracy: 0.9667\n",
            "Epoch 252/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.9750 - val_loss: 0.1228 - val_accuracy: 0.9667\n",
            "Epoch 253/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1130 - accuracy: 0.9833 - val_loss: 0.1222 - val_accuracy: 0.9667\n",
            "Epoch 254/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1123 - accuracy: 0.9833 - val_loss: 0.1220 - val_accuracy: 0.9667\n",
            "Epoch 255/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1120 - accuracy: 0.9833 - val_loss: 0.1210 - val_accuracy: 0.9667\n",
            "Epoch 256/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1113 - accuracy: 0.9833 - val_loss: 0.1211 - val_accuracy: 0.9667\n",
            "Epoch 257/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1107 - accuracy: 0.9833 - val_loss: 0.1207 - val_accuracy: 0.9667\n",
            "Epoch 258/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1102 - accuracy: 0.9833 - val_loss: 0.1200 - val_accuracy: 0.9667\n",
            "Epoch 259/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1098 - accuracy: 0.9833 - val_loss: 0.1195 - val_accuracy: 0.9667\n",
            "Epoch 260/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1090 - accuracy: 0.9833 - val_loss: 0.1195 - val_accuracy: 0.9667\n",
            "Epoch 261/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1086 - accuracy: 0.9750 - val_loss: 0.1195 - val_accuracy: 0.9667\n",
            "Epoch 262/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1080 - accuracy: 0.9750 - val_loss: 0.1188 - val_accuracy: 0.9667\n",
            "Epoch 263/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9750 - val_loss: 0.1180 - val_accuracy: 0.9667\n",
            "Epoch 264/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.9833 - val_loss: 0.1175 - val_accuracy: 0.9667\n",
            "Epoch 265/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1065 - accuracy: 0.9833 - val_loss: 0.1164 - val_accuracy: 0.9667\n",
            "Epoch 266/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1062 - accuracy: 0.9750 - val_loss: 0.1171 - val_accuracy: 0.9667\n",
            "Epoch 267/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9833 - val_loss: 0.1160 - val_accuracy: 0.9667\n",
            "Epoch 268/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1046 - accuracy: 0.9833 - val_loss: 0.1156 - val_accuracy: 0.9667\n",
            "Epoch 269/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1051 - accuracy: 0.9833 - val_loss: 0.1142 - val_accuracy: 0.9667\n",
            "Epoch 270/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.9833 - val_loss: 0.1147 - val_accuracy: 0.9667\n",
            "Epoch 271/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9833 - val_loss: 0.1150 - val_accuracy: 0.9667\n",
            "Epoch 272/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9750 - val_loss: 0.1148 - val_accuracy: 0.9667\n",
            "Epoch 273/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9833 - val_loss: 0.1133 - val_accuracy: 0.9667\n",
            "Epoch 274/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.9750 - val_loss: 0.1137 - val_accuracy: 0.9667\n",
            "Epoch 275/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1012 - accuracy: 0.9833 - val_loss: 0.1128 - val_accuracy: 0.9667\n",
            "Epoch 276/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1007 - accuracy: 0.9833 - val_loss: 0.1118 - val_accuracy: 0.9667\n",
            "Epoch 277/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1010 - accuracy: 0.9833 - val_loss: 0.1110 - val_accuracy: 0.9667\n",
            "Epoch 278/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.1000 - accuracy: 0.9833 - val_loss: 0.1118 - val_accuracy: 0.9667\n",
            "Epoch 279/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9833 - val_loss: 0.1110 - val_accuracy: 0.9667\n",
            "Epoch 280/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9833 - val_loss: 0.1100 - val_accuracy: 0.9667\n",
            "Epoch 281/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0986 - accuracy: 0.9833 - val_loss: 0.1110 - val_accuracy: 0.9667\n",
            "Epoch 282/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0981 - accuracy: 0.9833 - val_loss: 0.1101 - val_accuracy: 0.9667\n",
            "Epoch 283/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0975 - accuracy: 0.9833 - val_loss: 0.1097 - val_accuracy: 0.9667\n",
            "Epoch 284/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.9833 - val_loss: 0.1099 - val_accuracy: 0.9667\n",
            "Epoch 285/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0966 - accuracy: 0.9833 - val_loss: 0.1090 - val_accuracy: 0.9667\n",
            "Epoch 286/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0963 - accuracy: 0.9833 - val_loss: 0.1086 - val_accuracy: 0.9667\n",
            "Epoch 287/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0957 - accuracy: 0.9833 - val_loss: 0.1083 - val_accuracy: 0.9667\n",
            "Epoch 288/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0953 - accuracy: 0.9833 - val_loss: 0.1076 - val_accuracy: 0.9667\n",
            "Epoch 289/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0951 - accuracy: 0.9833 - val_loss: 0.1071 - val_accuracy: 0.9667\n",
            "Epoch 290/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9833 - val_loss: 0.1071 - val_accuracy: 0.9667\n",
            "Epoch 291/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9833 - val_loss: 0.1077 - val_accuracy: 0.9667\n",
            "Epoch 292/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0939 - accuracy: 0.9833 - val_loss: 0.1064 - val_accuracy: 0.9667\n",
            "Epoch 293/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9833 - val_loss: 0.1064 - val_accuracy: 0.9667\n",
            "Epoch 294/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 0.9833 - val_loss: 0.1057 - val_accuracy: 0.9667\n",
            "Epoch 295/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 0.9833 - val_loss: 0.1058 - val_accuracy: 0.9667\n",
            "Epoch 296/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0920 - accuracy: 0.9833 - val_loss: 0.1056 - val_accuracy: 0.9667\n",
            "Epoch 297/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0917 - accuracy: 0.9833 - val_loss: 0.1055 - val_accuracy: 0.9667\n",
            "Epoch 298/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0912 - accuracy: 0.9833 - val_loss: 0.1051 - val_accuracy: 0.9667\n",
            "Epoch 299/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0910 - accuracy: 0.9833 - val_loss: 0.1042 - val_accuracy: 0.9667\n",
            "Epoch 300/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0905 - accuracy: 0.9833 - val_loss: 0.1037 - val_accuracy: 0.9667\n",
            "Epoch 301/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0901 - accuracy: 0.9833 - val_loss: 0.1036 - val_accuracy: 0.9667\n",
            "Epoch 302/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0900 - accuracy: 0.9833 - val_loss: 0.1045 - val_accuracy: 0.9667\n",
            "Epoch 303/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0896 - accuracy: 0.9833 - val_loss: 0.1041 - val_accuracy: 0.9667\n",
            "Epoch 304/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0890 - accuracy: 0.9833 - val_loss: 0.1030 - val_accuracy: 0.9667\n",
            "Epoch 305/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0887 - accuracy: 0.9833 - val_loss: 0.1028 - val_accuracy: 0.9667\n",
            "Epoch 306/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0883 - accuracy: 0.9833 - val_loss: 0.1026 - val_accuracy: 0.9667\n",
            "Epoch 307/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0880 - accuracy: 0.9833 - val_loss: 0.1019 - val_accuracy: 0.9667\n",
            "Epoch 308/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0877 - accuracy: 0.9833 - val_loss: 0.1013 - val_accuracy: 0.9667\n",
            "Epoch 309/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0874 - accuracy: 0.9833 - val_loss: 0.1018 - val_accuracy: 0.9667\n",
            "Epoch 310/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0878 - accuracy: 0.9833 - val_loss: 0.1002 - val_accuracy: 0.9667\n",
            "Epoch 311/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.9833 - val_loss: 0.1018 - val_accuracy: 0.9667\n",
            "Epoch 312/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0866 - accuracy: 0.9833 - val_loss: 0.1004 - val_accuracy: 0.9667\n",
            "Epoch 313/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0858 - accuracy: 0.9833 - val_loss: 0.1001 - val_accuracy: 0.9667\n",
            "Epoch 314/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0856 - accuracy: 0.9833 - val_loss: 0.1010 - val_accuracy: 0.9667\n",
            "Epoch 315/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0859 - accuracy: 0.9833 - val_loss: 0.1014 - val_accuracy: 0.9667\n",
            "Epoch 316/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0849 - accuracy: 0.9833 - val_loss: 0.0999 - val_accuracy: 0.9667\n",
            "Epoch 317/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0845 - accuracy: 0.9833 - val_loss: 0.0996 - val_accuracy: 0.9667\n",
            "Epoch 318/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9833 - val_loss: 0.0983 - val_accuracy: 0.9667\n",
            "Epoch 319/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9833 - val_loss: 0.0991 - val_accuracy: 0.9667\n",
            "Epoch 320/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9833 - val_loss: 0.0988 - val_accuracy: 0.9667\n",
            "Epoch 321/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0833 - accuracy: 0.9833 - val_loss: 0.0982 - val_accuracy: 0.9667\n",
            "Epoch 322/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9833 - val_loss: 0.0990 - val_accuracy: 0.9667\n",
            "Epoch 323/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0829 - accuracy: 0.9833 - val_loss: 0.0993 - val_accuracy: 0.9667\n",
            "Epoch 324/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0826 - accuracy: 0.9833 - val_loss: 0.0976 - val_accuracy: 0.9667\n",
            "Epoch 325/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0820 - accuracy: 0.9833 - val_loss: 0.0974 - val_accuracy: 0.9667\n",
            "Epoch 326/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9833 - val_loss: 0.0971 - val_accuracy: 0.9667\n",
            "Epoch 327/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0815 - accuracy: 0.9833 - val_loss: 0.0967 - val_accuracy: 0.9667\n",
            "Epoch 328/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9833 - val_loss: 0.0968 - val_accuracy: 0.9667\n",
            "Epoch 329/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 0.9833 - val_loss: 0.0974 - val_accuracy: 0.9667\n",
            "Epoch 330/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 0.9833 - val_loss: 0.0962 - val_accuracy: 0.9667\n",
            "Epoch 331/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0804 - accuracy: 0.9833 - val_loss: 0.0965 - val_accuracy: 0.9667\n",
            "Epoch 332/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9833 - val_loss: 0.0958 - val_accuracy: 0.9667\n",
            "Epoch 333/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9833 - val_loss: 0.0960 - val_accuracy: 0.9667\n",
            "Epoch 334/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0793 - accuracy: 0.9833 - val_loss: 0.0958 - val_accuracy: 0.9667\n",
            "Epoch 335/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0790 - accuracy: 0.9833 - val_loss: 0.0957 - val_accuracy: 0.9667\n",
            "Epoch 336/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0789 - accuracy: 0.9833 - val_loss: 0.0964 - val_accuracy: 0.9667\n",
            "Epoch 337/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0788 - accuracy: 0.9833 - val_loss: 0.0968 - val_accuracy: 0.9667\n",
            "Epoch 338/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0783 - accuracy: 0.9833 - val_loss: 0.0952 - val_accuracy: 0.9667\n",
            "Epoch 339/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0779 - accuracy: 0.9833 - val_loss: 0.0947 - val_accuracy: 0.9667\n",
            "Epoch 340/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9833 - val_loss: 0.0942 - val_accuracy: 0.9667\n",
            "Epoch 341/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0775 - accuracy: 0.9833 - val_loss: 0.0947 - val_accuracy: 0.9667\n",
            "Epoch 342/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9833 - val_loss: 0.0949 - val_accuracy: 0.9667\n",
            "Epoch 343/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0769 - accuracy: 0.9833 - val_loss: 0.0942 - val_accuracy: 0.9667\n",
            "Epoch 344/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0769 - accuracy: 0.9833 - val_loss: 0.0944 - val_accuracy: 0.9667\n",
            "Epoch 345/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0764 - accuracy: 0.9833 - val_loss: 0.0930 - val_accuracy: 0.9667\n",
            "Epoch 346/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0763 - accuracy: 0.9833 - val_loss: 0.0931 - val_accuracy: 0.9667\n",
            "Epoch 347/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9833 - val_loss: 0.0932 - val_accuracy: 0.9667\n",
            "Epoch 348/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9833 - val_loss: 0.0925 - val_accuracy: 0.9667\n",
            "Epoch 349/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0752 - accuracy: 0.9833 - val_loss: 0.0927 - val_accuracy: 0.9667\n",
            "Epoch 350/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9833 - val_loss: 0.0922 - val_accuracy: 0.9667\n",
            "Epoch 351/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9833 - val_loss: 0.0930 - val_accuracy: 0.9667\n",
            "Epoch 352/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0746 - accuracy: 0.9833 - val_loss: 0.0932 - val_accuracy: 0.9667\n",
            "Epoch 353/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0745 - accuracy: 0.9833 - val_loss: 0.0920 - val_accuracy: 0.9667\n",
            "Epoch 354/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0740 - accuracy: 0.9833 - val_loss: 0.0922 - val_accuracy: 0.9667\n",
            "Epoch 355/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.9833 - val_loss: 0.0930 - val_accuracy: 0.9667\n",
            "Epoch 356/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0736 - accuracy: 0.9833 - val_loss: 0.0922 - val_accuracy: 0.9667\n",
            "Epoch 357/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0734 - accuracy: 0.9833 - val_loss: 0.0920 - val_accuracy: 0.9667\n",
            "Epoch 358/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0731 - accuracy: 0.9833 - val_loss: 0.0911 - val_accuracy: 0.9667\n",
            "Epoch 359/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0728 - accuracy: 0.9833 - val_loss: 0.0908 - val_accuracy: 0.9667\n",
            "Epoch 360/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9833 - val_loss: 0.0915 - val_accuracy: 0.9667\n",
            "Epoch 361/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.9833 - val_loss: 0.0921 - val_accuracy: 0.9667\n",
            "Epoch 362/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9833 - val_loss: 0.0908 - val_accuracy: 0.9667\n",
            "Epoch 363/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9833 - val_loss: 0.0912 - val_accuracy: 0.9667\n",
            "Epoch 364/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0722 - accuracy: 0.9833 - val_loss: 0.0898 - val_accuracy: 0.9667\n",
            "Epoch 365/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9833 - val_loss: 0.0910 - val_accuracy: 0.9667\n",
            "Epoch 366/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9833 - val_loss: 0.0904 - val_accuracy: 0.9667\n",
            "Epoch 367/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0716 - accuracy: 0.9833 - val_loss: 0.0918 - val_accuracy: 0.9667\n",
            "Epoch 368/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0713 - accuracy: 0.9833 - val_loss: 0.0893 - val_accuracy: 0.9667\n",
            "Epoch 369/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9833 - val_loss: 0.0891 - val_accuracy: 0.9667\n",
            "Epoch 370/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9833 - val_loss: 0.0898 - val_accuracy: 0.9667\n",
            "Epoch 371/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0702 - accuracy: 0.9833 - val_loss: 0.0902 - val_accuracy: 0.9667\n",
            "Epoch 372/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9833 - val_loss: 0.0902 - val_accuracy: 0.9667\n",
            "Epoch 373/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0699 - accuracy: 0.9833 - val_loss: 0.0909 - val_accuracy: 0.9667\n",
            "Epoch 374/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0696 - accuracy: 0.9833 - val_loss: 0.0900 - val_accuracy: 0.9667\n",
            "Epoch 375/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0691 - accuracy: 0.9833 - val_loss: 0.0891 - val_accuracy: 0.9667\n",
            "Epoch 376/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9833 - val_loss: 0.0893 - val_accuracy: 0.9667\n",
            "Epoch 377/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0688 - accuracy: 0.9833 - val_loss: 0.0885 - val_accuracy: 0.9667\n",
            "Epoch 378/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0693 - accuracy: 0.9833 - val_loss: 0.0901 - val_accuracy: 0.9667\n",
            "Epoch 379/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0683 - accuracy: 0.9833 - val_loss: 0.0890 - val_accuracy: 0.9667\n",
            "Epoch 380/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0682 - accuracy: 0.9833 - val_loss: 0.0881 - val_accuracy: 0.9667\n",
            "Epoch 381/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0680 - accuracy: 0.9833 - val_loss: 0.0887 - val_accuracy: 0.9667\n",
            "Epoch 382/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9833 - val_loss: 0.0889 - val_accuracy: 0.9667\n",
            "Epoch 383/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9833 - val_loss: 0.0883 - val_accuracy: 0.9667\n",
            "Epoch 384/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9833 - val_loss: 0.0886 - val_accuracy: 0.9667\n",
            "Epoch 385/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9833 - val_loss: 0.0883 - val_accuracy: 0.9667\n",
            "Epoch 386/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9833 - val_loss: 0.0894 - val_accuracy: 0.9667\n",
            "Epoch 387/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0667 - accuracy: 0.9833 - val_loss: 0.0891 - val_accuracy: 0.9667\n",
            "Epoch 388/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9833 - val_loss: 0.0872 - val_accuracy: 0.9667\n",
            "Epoch 389/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0663 - accuracy: 0.9833 - val_loss: 0.0873 - val_accuracy: 0.9667\n",
            "Epoch 390/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0661 - accuracy: 0.9833 - val_loss: 0.0874 - val_accuracy: 0.9667\n",
            "Epoch 391/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9833 - val_loss: 0.0882 - val_accuracy: 0.9667\n",
            "Epoch 392/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9833 - val_loss: 0.0887 - val_accuracy: 0.9667\n",
            "Epoch 393/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0655 - accuracy: 0.9833 - val_loss: 0.0883 - val_accuracy: 0.9667\n",
            "Epoch 394/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0653 - accuracy: 0.9833 - val_loss: 0.0873 - val_accuracy: 0.9667\n",
            "Epoch 395/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9833 - val_loss: 0.0876 - val_accuracy: 0.9667\n",
            "Epoch 396/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9833 - val_loss: 0.0864 - val_accuracy: 0.9667\n",
            "Epoch 397/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0648 - accuracy: 0.9833 - val_loss: 0.0861 - val_accuracy: 0.9667\n",
            "Epoch 398/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0647 - accuracy: 0.9833 - val_loss: 0.0877 - val_accuracy: 0.9667\n",
            "Epoch 399/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9833 - val_loss: 0.0877 - val_accuracy: 0.9667\n",
            "Epoch 400/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9833 - val_loss: 0.0871 - val_accuracy: 0.9667\n",
            "Epoch 401/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0642 - accuracy: 0.9833 - val_loss: 0.0863 - val_accuracy: 0.9667\n",
            "Epoch 402/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9833 - val_loss: 0.0866 - val_accuracy: 0.9667\n",
            "Epoch 403/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9833 - val_loss: 0.0862 - val_accuracy: 0.9667\n",
            "Epoch 404/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0635 - accuracy: 0.9833 - val_loss: 0.0869 - val_accuracy: 0.9667\n",
            "Epoch 405/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0634 - accuracy: 0.9833 - val_loss: 0.0860 - val_accuracy: 0.9667\n",
            "Epoch 406/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0631 - accuracy: 0.9833 - val_loss: 0.0866 - val_accuracy: 0.9667\n",
            "Epoch 407/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9833 - val_loss: 0.0866 - val_accuracy: 0.9667\n",
            "Epoch 408/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0632 - accuracy: 0.9833 - val_loss: 0.0855 - val_accuracy: 0.9667\n",
            "Epoch 409/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0626 - accuracy: 0.9833 - val_loss: 0.0858 - val_accuracy: 0.9667\n",
            "Epoch 410/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9833 - val_loss: 0.0867 - val_accuracy: 0.9667\n",
            "Epoch 411/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9833 - val_loss: 0.0865 - val_accuracy: 0.9667\n",
            "Epoch 412/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0622 - accuracy: 0.9833 - val_loss: 0.0869 - val_accuracy: 0.9667\n",
            "Epoch 413/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9833 - val_loss: 0.0862 - val_accuracy: 0.9667\n",
            "Epoch 414/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0620 - accuracy: 0.9833 - val_loss: 0.0849 - val_accuracy: 0.9667\n",
            "Epoch 415/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0617 - accuracy: 0.9833 - val_loss: 0.0856 - val_accuracy: 0.9667\n",
            "Epoch 416/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9833 - val_loss: 0.0858 - val_accuracy: 0.9667\n",
            "Epoch 417/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0614 - accuracy: 0.9833 - val_loss: 0.0855 - val_accuracy: 0.9667\n",
            "Epoch 418/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9833 - val_loss: 0.0863 - val_accuracy: 0.9667\n",
            "Epoch 419/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0611 - accuracy: 0.9833 - val_loss: 0.0862 - val_accuracy: 0.9667\n",
            "Epoch 420/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0612 - accuracy: 0.9833 - val_loss: 0.0864 - val_accuracy: 0.9667\n",
            "Epoch 421/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9833 - val_loss: 0.0842 - val_accuracy: 0.9667\n",
            "Epoch 422/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9833 - val_loss: 0.0853 - val_accuracy: 0.9667\n",
            "Epoch 423/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0605 - accuracy: 0.9833 - val_loss: 0.0856 - val_accuracy: 0.9667\n",
            "Epoch 424/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0610 - accuracy: 0.9833 - val_loss: 0.0840 - val_accuracy: 0.9667\n",
            "Epoch 425/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9833 - val_loss: 0.0844 - val_accuracy: 0.9667\n",
            "Epoch 426/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0601 - accuracy: 0.9833 - val_loss: 0.0853 - val_accuracy: 0.9667\n",
            "Epoch 427/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9833 - val_loss: 0.0844 - val_accuracy: 0.9667\n",
            "Epoch 428/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0598 - accuracy: 0.9833 - val_loss: 0.0854 - val_accuracy: 0.9667\n",
            "Epoch 429/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9833 - val_loss: 0.0845 - val_accuracy: 0.9667\n",
            "Epoch 430/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0594 - accuracy: 0.9833 - val_loss: 0.0844 - val_accuracy: 0.9667\n",
            "Epoch 431/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0591 - accuracy: 0.9833 - val_loss: 0.0851 - val_accuracy: 0.9667\n",
            "Epoch 432/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0593 - accuracy: 0.9833 - val_loss: 0.0841 - val_accuracy: 0.9667\n",
            "Epoch 433/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0589 - accuracy: 0.9833 - val_loss: 0.0852 - val_accuracy: 0.9667\n",
            "Epoch 434/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0590 - accuracy: 0.9833 - val_loss: 0.0858 - val_accuracy: 0.9667\n",
            "Epoch 435/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0586 - accuracy: 0.9833 - val_loss: 0.0848 - val_accuracy: 0.9667\n",
            "Epoch 436/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9833 - val_loss: 0.0842 - val_accuracy: 0.9667\n",
            "Epoch 437/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0588 - accuracy: 0.9833 - val_loss: 0.0852 - val_accuracy: 0.9667\n",
            "Epoch 438/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0584 - accuracy: 0.9833 - val_loss: 0.0838 - val_accuracy: 0.9667\n",
            "Epoch 439/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0581 - accuracy: 0.9833 - val_loss: 0.0842 - val_accuracy: 0.9667\n",
            "Epoch 440/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0579 - accuracy: 0.9833 - val_loss: 0.0838 - val_accuracy: 0.9667\n",
            "Epoch 441/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0582 - accuracy: 0.9833 - val_loss: 0.0826 - val_accuracy: 0.9667\n",
            "Epoch 442/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9833 - val_loss: 0.0834 - val_accuracy: 0.9667\n",
            "Epoch 443/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0577 - accuracy: 0.9833 - val_loss: 0.0852 - val_accuracy: 0.9667\n",
            "Epoch 444/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9833 - val_loss: 0.0842 - val_accuracy: 0.9667\n",
            "Epoch 445/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9833 - val_loss: 0.0850 - val_accuracy: 0.9667\n",
            "Epoch 446/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.9833 - val_loss: 0.0835 - val_accuracy: 0.9667\n",
            "Epoch 447/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9833 - val_loss: 0.0833 - val_accuracy: 0.9667\n",
            "Epoch 448/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0571 - accuracy: 0.9833 - val_loss: 0.0850 - val_accuracy: 0.9667\n",
            "Epoch 449/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9833 - val_loss: 0.0836 - val_accuracy: 0.9667\n",
            "Epoch 450/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0570 - accuracy: 0.9833 - val_loss: 0.0823 - val_accuracy: 0.9667\n",
            "Epoch 451/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9833 - val_loss: 0.0837 - val_accuracy: 0.9667\n",
            "Epoch 452/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9833 - val_loss: 0.0844 - val_accuracy: 0.9667\n",
            "Epoch 453/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9833 - val_loss: 0.0841 - val_accuracy: 0.9667\n",
            "Epoch 454/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0564 - accuracy: 0.9833 - val_loss: 0.0848 - val_accuracy: 0.9667\n",
            "Epoch 455/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9833 - val_loss: 0.0836 - val_accuracy: 0.9667\n",
            "Epoch 456/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9833 - val_loss: 0.0844 - val_accuracy: 0.9667\n",
            "Epoch 457/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9833 - val_loss: 0.0827 - val_accuracy: 0.9667\n",
            "Epoch 458/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9833 - val_loss: 0.0845 - val_accuracy: 0.9667\n",
            "Epoch 459/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0560 - accuracy: 0.9833 - val_loss: 0.0851 - val_accuracy: 0.9667\n",
            "Epoch 460/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0552 - accuracy: 0.9833 - val_loss: 0.0837 - val_accuracy: 0.9667\n",
            "Epoch 461/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9833 - val_loss: 0.0825 - val_accuracy: 0.9667\n",
            "Epoch 462/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9833 - val_loss: 0.0831 - val_accuracy: 0.9667\n",
            "Epoch 463/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9833 - val_loss: 0.0832 - val_accuracy: 0.9667\n",
            "Epoch 464/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9833 - val_loss: 0.0835 - val_accuracy: 0.9667\n",
            "Epoch 465/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9833 - val_loss: 0.0833 - val_accuracy: 0.9667\n",
            "Epoch 466/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0547 - accuracy: 0.9833 - val_loss: 0.0839 - val_accuracy: 0.9667\n",
            "Epoch 467/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9833 - val_loss: 0.0817 - val_accuracy: 0.9667\n",
            "Epoch 468/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0546 - accuracy: 0.9833 - val_loss: 0.0815 - val_accuracy: 0.9667\n",
            "Epoch 469/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9833 - val_loss: 0.0828 - val_accuracy: 0.9667\n",
            "Epoch 470/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9833 - val_loss: 0.0838 - val_accuracy: 0.9667\n",
            "Epoch 471/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9833 - val_loss: 0.0842 - val_accuracy: 0.9667\n",
            "Epoch 472/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9833 - val_loss: 0.0842 - val_accuracy: 0.9667\n",
            "Epoch 473/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9833 - val_loss: 0.0828 - val_accuracy: 0.9667\n",
            "Epoch 474/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0538 - accuracy: 0.9833 - val_loss: 0.0829 - val_accuracy: 0.9667\n",
            "Epoch 475/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9833 - val_loss: 0.0825 - val_accuracy: 0.9667\n",
            "Epoch 476/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9833 - val_loss: 0.0818 - val_accuracy: 0.9667\n",
            "Epoch 477/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9833 - val_loss: 0.0823 - val_accuracy: 0.9667\n",
            "Epoch 478/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9833 - val_loss: 0.0843 - val_accuracy: 0.9667\n",
            "Epoch 479/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0532 - accuracy: 0.9833 - val_loss: 0.0829 - val_accuracy: 0.9667\n",
            "Epoch 480/500\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0530 - accuracy: 0.9833 - val_loss: 0.0828 - val_accuracy: 0.9667\n",
            "Epoch 481/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9833 - val_loss: 0.0830 - val_accuracy: 0.9667\n",
            "Epoch 482/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0528 - accuracy: 0.9833 - val_loss: 0.0823 - val_accuracy: 0.9667\n",
            "Epoch 483/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9833 - val_loss: 0.0837 - val_accuracy: 0.9667\n",
            "Epoch 484/500\n",
            "12/12 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.9833 - val_loss: 0.0823 - val_accuracy: 0.9667\n",
            "Epoch 485/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9833 - val_loss: 0.0834 - val_accuracy: 0.9667\n",
            "Epoch 486/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0523 - accuracy: 0.9833 - val_loss: 0.0838 - val_accuracy: 0.9667\n",
            "Epoch 487/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9833 - val_loss: 0.0828 - val_accuracy: 0.9667\n",
            "Epoch 488/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9833 - val_loss: 0.0817 - val_accuracy: 0.9667\n",
            "Epoch 489/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9833 - val_loss: 0.0821 - val_accuracy: 0.9667\n",
            "Epoch 490/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9833 - val_loss: 0.0826 - val_accuracy: 0.9667\n",
            "Epoch 491/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9833 - val_loss: 0.0832 - val_accuracy: 0.9667\n",
            "Epoch 492/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0518 - accuracy: 0.9833 - val_loss: 0.0830 - val_accuracy: 0.9667\n",
            "Epoch 493/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0517 - accuracy: 0.9833 - val_loss: 0.0839 - val_accuracy: 0.9667\n",
            "Epoch 494/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0522 - accuracy: 0.9833 - val_loss: 0.0815 - val_accuracy: 0.9667\n",
            "Epoch 495/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9833 - val_loss: 0.0825 - val_accuracy: 0.9667\n",
            "Epoch 496/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0514 - accuracy: 0.9833 - val_loss: 0.0823 - val_accuracy: 0.9667\n",
            "Epoch 497/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9833 - val_loss: 0.0834 - val_accuracy: 0.9667\n",
            "Epoch 498/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9833 - val_loss: 0.0824 - val_accuracy: 0.9667\n",
            "Epoch 499/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0512 - accuracy: 0.9833 - val_loss: 0.0827 - val_accuracy: 0.9667\n",
            "Epoch 500/500\n",
            "12/12 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9833 - val_loss: 0.0836 - val_accuracy: 0.9667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsTL70Lpzkmi",
        "outputId": "035fcb1d-09ae-48db-b603-7eb75bcd1318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history.history"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [0.2916666567325592,\n",
              "  0.3333333432674408,\n",
              "  0.375,\n",
              "  0.4333333373069763,\n",
              "  0.49166667461395264,\n",
              "  0.550000011920929,\n",
              "  0.5583333373069763,\n",
              "  0.574999988079071,\n",
              "  0.6166666746139526,\n",
              "  0.625,\n",
              "  0.6333333253860474,\n",
              "  0.6583333611488342,\n",
              "  0.6583333611488342,\n",
              "  0.6666666865348816,\n",
              "  0.6666666865348816,\n",
              "  0.675000011920929,\n",
              "  0.675000011920929,\n",
              "  0.675000011920929,\n",
              "  0.6833333373069763,\n",
              "  0.6833333373069763,\n",
              "  0.6833333373069763,\n",
              "  0.6916666626930237,\n",
              "  0.6916666626930237,\n",
              "  0.6833333373069763,\n",
              "  0.6833333373069763,\n",
              "  0.6833333373069763,\n",
              "  0.6916666626930237,\n",
              "  0.6916666626930237,\n",
              "  0.6916666626930237,\n",
              "  0.699999988079071,\n",
              "  0.7083333134651184,\n",
              "  0.7083333134651184,\n",
              "  0.7083333134651184,\n",
              "  0.7166666388511658,\n",
              "  0.7416666746139526,\n",
              "  0.75,\n",
              "  0.7666666507720947,\n",
              "  0.7833333611488342,\n",
              "  0.7916666865348816,\n",
              "  0.7916666865348816,\n",
              "  0.800000011920929,\n",
              "  0.8083333373069763,\n",
              "  0.8083333373069763,\n",
              "  0.8083333373069763,\n",
              "  0.8083333373069763,\n",
              "  0.8083333373069763,\n",
              "  0.8083333373069763,\n",
              "  0.8083333373069763,\n",
              "  0.8083333373069763,\n",
              "  0.8083333373069763,\n",
              "  0.8083333373069763,\n",
              "  0.8083333373069763,\n",
              "  0.8083333373069763,\n",
              "  0.8083333373069763,\n",
              "  0.8166666626930237,\n",
              "  0.8166666626930237,\n",
              "  0.824999988079071,\n",
              "  0.824999988079071,\n",
              "  0.8333333134651184,\n",
              "  0.8416666388511658,\n",
              "  0.8416666388511658,\n",
              "  0.8416666388511658,\n",
              "  0.8416666388511658,\n",
              "  0.8416666388511658,\n",
              "  0.8416666388511658,\n",
              "  0.8500000238418579,\n",
              "  0.8500000238418579,\n",
              "  0.8416666388511658,\n",
              "  0.8416666388511658,\n",
              "  0.8583333492279053,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.875,\n",
              "  0.875,\n",
              "  0.875,\n",
              "  0.875,\n",
              "  0.875,\n",
              "  0.875,\n",
              "  0.8833333253860474,\n",
              "  0.8833333253860474,\n",
              "  0.8916666507720947,\n",
              "  0.8916666507720947,\n",
              "  0.8916666507720947,\n",
              "  0.8999999761581421,\n",
              "  0.8999999761581421,\n",
              "  0.9083333611488342,\n",
              "  0.9166666865348816,\n",
              "  0.9166666865348816,\n",
              "  0.9166666865348816,\n",
              "  0.9166666865348816,\n",
              "  0.9166666865348816,\n",
              "  0.9166666865348816,\n",
              "  0.9166666865348816,\n",
              "  0.9166666865348816,\n",
              "  0.9166666865348816,\n",
              "  0.925000011920929,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9416666626930237,\n",
              "  0.9416666626930237,\n",
              "  0.9416666626930237,\n",
              "  0.9416666626930237,\n",
              "  0.9416666626930237,\n",
              "  0.949999988079071,\n",
              "  0.949999988079071,\n",
              "  0.949999988079071,\n",
              "  0.949999988079071,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9583333134651184,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9750000238418579,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9750000238418579,\n",
              "  0.9750000238418579,\n",
              "  0.9750000238418579,\n",
              "  0.9750000238418579,\n",
              "  0.9750000238418579,\n",
              "  0.9750000238418579,\n",
              "  0.9750000238418579],\n",
              " 'loss': [1.2485848665237427,\n",
              "  1.2041610479354858,\n",
              "  1.1646894216537476,\n",
              "  1.1261392831802368,\n",
              "  1.0909651517868042,\n",
              "  1.0574395656585693,\n",
              "  1.0266222953796387,\n",
              "  0.9972644448280334,\n",
              "  0.9689944982528687,\n",
              "  0.9426885843276978,\n",
              "  0.9184693694114685,\n",
              "  0.8948021531105042,\n",
              "  0.871051013469696,\n",
              "  0.8490327596664429,\n",
              "  0.8272382020950317,\n",
              "  0.8070127964019775,\n",
              "  0.7867938876152039,\n",
              "  0.767309308052063,\n",
              "  0.7483677268028259,\n",
              "  0.7307652831077576,\n",
              "  0.712737500667572,\n",
              "  0.6965504288673401,\n",
              "  0.6812209486961365,\n",
              "  0.6668319702148438,\n",
              "  0.6521730422973633,\n",
              "  0.6392715573310852,\n",
              "  0.626541256904602,\n",
              "  0.6150102019309998,\n",
              "  0.6039395928382874,\n",
              "  0.5935033559799194,\n",
              "  0.5837234854698181,\n",
              "  0.5739437341690063,\n",
              "  0.5652863383293152,\n",
              "  0.5569620132446289,\n",
              "  0.5487106442451477,\n",
              "  0.5411054491996765,\n",
              "  0.5337662100791931,\n",
              "  0.5267288684844971,\n",
              "  0.520106315612793,\n",
              "  0.51360023021698,\n",
              "  0.5073974132537842,\n",
              "  0.5015453696250916,\n",
              "  0.4953678250312805,\n",
              "  0.4896240830421448,\n",
              "  0.48383447527885437,\n",
              "  0.47863155603408813,\n",
              "  0.47328120470046997,\n",
              "  0.46770983934402466,\n",
              "  0.4628957211971283,\n",
              "  0.45781370997428894,\n",
              "  0.4527835249900818,\n",
              "  0.44823020696640015,\n",
              "  0.4433804154396057,\n",
              "  0.4391319453716278,\n",
              "  0.43410632014274597,\n",
              "  0.4298097789287567,\n",
              "  0.42540472745895386,\n",
              "  0.42066895961761475,\n",
              "  0.41636037826538086,\n",
              "  0.4117838740348816,\n",
              "  0.40720081329345703,\n",
              "  0.4027230441570282,\n",
              "  0.3983210623264313,\n",
              "  0.39366233348846436,\n",
              "  0.38926634192466736,\n",
              "  0.385071724653244,\n",
              "  0.3806833028793335,\n",
              "  0.3760558068752289,\n",
              "  0.3717248737812042,\n",
              "  0.36754319071769714,\n",
              "  0.3631414473056793,\n",
              "  0.3585517704486847,\n",
              "  0.35421159863471985,\n",
              "  0.3500543236732483,\n",
              "  0.3459305167198181,\n",
              "  0.341798335313797,\n",
              "  0.3378514349460602,\n",
              "  0.33409059047698975,\n",
              "  0.33018118143081665,\n",
              "  0.3261612355709076,\n",
              "  0.3223676085472107,\n",
              "  0.3183455467224121,\n",
              "  0.3143709897994995,\n",
              "  0.3107825517654419,\n",
              "  0.30708566308021545,\n",
              "  0.30344584584236145,\n",
              "  0.3004242479801178,\n",
              "  0.29613953828811646,\n",
              "  0.2927667200565338,\n",
              "  0.28899967670440674,\n",
              "  0.2849590480327606,\n",
              "  0.28109702467918396,\n",
              "  0.27705663442611694,\n",
              "  0.2738015353679657,\n",
              "  0.26955363154411316,\n",
              "  0.26610884070396423,\n",
              "  0.2627124488353729,\n",
              "  0.2590857446193695,\n",
              "  0.2556951344013214,\n",
              "  0.2524149715900421,\n",
              "  0.24907764792442322,\n",
              "  0.24601931869983673,\n",
              "  0.24253016710281372,\n",
              "  0.23953348398208618,\n",
              "  0.23654550313949585,\n",
              "  0.23354890942573547,\n",
              "  0.230641171336174,\n",
              "  0.22833099961280823,\n",
              "  0.22501058876514435,\n",
              "  0.222761332988739,\n",
              "  0.2195178121328354,\n",
              "  0.21699851751327515,\n",
              "  0.21443083882331848,\n",
              "  0.21187305450439453,\n",
              "  0.20935110747814178,\n",
              "  0.20703451335430145,\n",
              "  0.20448066294193268,\n",
              "  0.2021789401769638,\n",
              "  0.19993789494037628,\n",
              "  0.19772502779960632,\n",
              "  0.19518177211284637,\n",
              "  0.19321057200431824,\n",
              "  0.1911485344171524,\n",
              "  0.1888011395931244,\n",
              "  0.18682847917079926,\n",
              "  0.1847335547208786,\n",
              "  0.18288347125053406,\n",
              "  0.1806737631559372,\n",
              "  0.1790468841791153,\n",
              "  0.1769891381263733,\n",
              "  0.1754838526248932,\n",
              "  0.17397545278072357,\n",
              "  0.17141848802566528,\n",
              "  0.16974478960037231,\n",
              "  0.16802194714546204,\n",
              "  0.16638222336769104,\n",
              "  0.1647854894399643,\n",
              "  0.16302455961704254,\n",
              "  0.16197563707828522,\n",
              "  0.15997661650180817,\n",
              "  0.15807287395000458,\n",
              "  0.1565181165933609,\n",
              "  0.15521101653575897,\n",
              "  0.15346072614192963,\n",
              "  0.15259908139705658,\n",
              "  0.15028244256973267,\n",
              "  0.14893978834152222,\n",
              "  0.14775557816028595,\n",
              "  0.1461540311574936,\n",
              "  0.14498497545719147,\n",
              "  0.14349740743637085,\n",
              "  0.14245955646038055,\n",
              "  0.14080668985843658,\n",
              "  0.1396940052509308,\n",
              "  0.1383330225944519,\n",
              "  0.1371311992406845,\n",
              "  0.1360042542219162,\n",
              "  0.13479618728160858,\n",
              "  0.1336374133825302,\n",
              "  0.13254064321517944,\n",
              "  0.1318698674440384,\n",
              "  0.1301221400499344,\n",
              "  0.1291705220937729,\n",
              "  0.12808065116405487,\n",
              "  0.12745939195156097,\n",
              "  0.1261790543794632,\n",
              "  0.12491807341575623,\n",
              "  0.12397577613592148,\n",
              "  0.1232740730047226,\n",
              "  0.1223335936665535,\n",
              "  0.12119483202695847,\n",
              "  0.12012093514204025,\n",
              "  0.11914114654064178,\n",
              "  0.11830589175224304,\n",
              "  0.11750730127096176,\n",
              "  0.11667247861623764,\n",
              "  0.11560370028018951,\n",
              "  0.11490242928266525,\n",
              "  0.1143740639090538,\n",
              "  0.11323311179876328,\n",
              "  0.11236084252595901,\n",
              "  0.11152016371488571,\n",
              "  0.11086723953485489,\n",
              "  0.11021991819143295,\n",
              "  0.10921703279018402,\n",
              "  0.10936381667852402,\n",
              "  0.10785805433988571,\n",
              "  0.10700580477714539,\n",
              "  0.10641445964574814,\n",
              "  0.10580376535654068,\n",
              "  0.10491853207349777,\n",
              "  0.10435520857572556,\n",
              "  0.10361483693122864,\n",
              "  0.10303545743227005,\n",
              "  0.10257614403963089,\n",
              "  0.1018252745270729,\n",
              "  0.10101873427629471,\n",
              "  0.10047753155231476,\n",
              "  0.10014799237251282,\n",
              "  0.09912978857755661],\n",
              " 'val_accuracy': [0.5,\n",
              "  0.5333333611488342,\n",
              "  0.5666666626930237,\n",
              "  0.6000000238418579,\n",
              "  0.6000000238418579,\n",
              "  0.6000000238418579,\n",
              "  0.6333333253860474,\n",
              "  0.6666666865348816,\n",
              "  0.6666666865348816,\n",
              "  0.6666666865348816,\n",
              "  0.6666666865348816,\n",
              "  0.6666666865348816,\n",
              "  0.699999988079071,\n",
              "  0.699999988079071,\n",
              "  0.699999988079071,\n",
              "  0.699999988079071,\n",
              "  0.699999988079071,\n",
              "  0.699999988079071,\n",
              "  0.7333333492279053,\n",
              "  0.7333333492279053,\n",
              "  0.7333333492279053,\n",
              "  0.7333333492279053,\n",
              "  0.7333333492279053,\n",
              "  0.7333333492279053,\n",
              "  0.7333333492279053,\n",
              "  0.7333333492279053,\n",
              "  0.7333333492279053,\n",
              "  0.7333333492279053,\n",
              "  0.7333333492279053,\n",
              "  0.7333333492279053,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7333333492279053,\n",
              "  0.7333333492279053,\n",
              "  0.7333333492279053,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.7666666507720947,\n",
              "  0.800000011920929,\n",
              "  0.800000011920929,\n",
              "  0.800000011920929,\n",
              "  0.8333333134651184,\n",
              "  0.8333333134651184,\n",
              "  0.8333333134651184,\n",
              "  0.8333333134651184,\n",
              "  0.8333333134651184,\n",
              "  0.8333333134651184,\n",
              "  0.8333333134651184,\n",
              "  0.8333333134651184,\n",
              "  0.8333333134651184,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.8666666746139526,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9333333373069763,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658,\n",
              "  0.9666666388511658],\n",
              " 'val_loss': [1.1077088117599487,\n",
              "  1.0666805505752563,\n",
              "  1.0257623195648193,\n",
              "  0.988498330116272,\n",
              "  0.9542253017425537,\n",
              "  0.9219977259635925,\n",
              "  0.8906804919242859,\n",
              "  0.8608103394508362,\n",
              "  0.8342252969741821,\n",
              "  0.8096247315406799,\n",
              "  0.7857350707054138,\n",
              "  0.76276695728302,\n",
              "  0.7409856915473938,\n",
              "  0.720340371131897,\n",
              "  0.7013803124427795,\n",
              "  0.6826065182685852,\n",
              "  0.6648208498954773,\n",
              "  0.6476150155067444,\n",
              "  0.6316179633140564,\n",
              "  0.6166797280311584,\n",
              "  0.6023272275924683,\n",
              "  0.5891790986061096,\n",
              "  0.5766344666481018,\n",
              "  0.5651506185531616,\n",
              "  0.5543558597564697,\n",
              "  0.5439403653144836,\n",
              "  0.5343809127807617,\n",
              "  0.5256235003471375,\n",
              "  0.5171915292739868,\n",
              "  0.5093590021133423,\n",
              "  0.5019514560699463,\n",
              "  0.4948635697364807,\n",
              "  0.4881027638912201,\n",
              "  0.48211124539375305,\n",
              "  0.47614622116088867,\n",
              "  0.47053420543670654,\n",
              "  0.46507611870765686,\n",
              "  0.45979347825050354,\n",
              "  0.4547173082828522,\n",
              "  0.4498447775840759,\n",
              "  0.4452045261859894,\n",
              "  0.4401664733886719,\n",
              "  0.4358406066894531,\n",
              "  0.43163782358169556,\n",
              "  0.4275374710559845,\n",
              "  0.42326024174690247,\n",
              "  0.41916030645370483,\n",
              "  0.41532886028289795,\n",
              "  0.4113701581954956,\n",
              "  0.40781205892562866,\n",
              "  0.40454572439193726,\n",
              "  0.401115745306015,\n",
              "  0.3977277874946594,\n",
              "  0.3940710425376892,\n",
              "  0.3912102282047272,\n",
              "  0.388107031583786,\n",
              "  0.38503721356391907,\n",
              "  0.38190022110939026,\n",
              "  0.3787296414375305,\n",
              "  0.37551769614219666,\n",
              "  0.37211543321609497,\n",
              "  0.36881983280181885,\n",
              "  0.36547333002090454,\n",
              "  0.3622588813304901,\n",
              "  0.35915279388427734,\n",
              "  0.35596370697021484,\n",
              "  0.35264191031455994,\n",
              "  0.3496575951576233,\n",
              "  0.3468010723590851,\n",
              "  0.34342527389526367,\n",
              "  0.33991509675979614,\n",
              "  0.33746013045310974,\n",
              "  0.33435070514678955,\n",
              "  0.3311094343662262,\n",
              "  0.3283706605434418,\n",
              "  0.32524973154067993,\n",
              "  0.32214242219924927,\n",
              "  0.31905561685562134,\n",
              "  0.3164704144001007,\n",
              "  0.3130561113357544,\n",
              "  0.31061822175979614,\n",
              "  0.30759531259536743,\n",
              "  0.30470821261405945,\n",
              "  0.30133718252182007,\n",
              "  0.299090713262558,\n",
              "  0.296305388212204,\n",
              "  0.29292479157447815,\n",
              "  0.2903337776660919,\n",
              "  0.28650951385498047,\n",
              "  0.28332334756851196,\n",
              "  0.2795681357383728,\n",
              "  0.27607837319374084,\n",
              "  0.27225029468536377,\n",
              "  0.2678591012954712,\n",
              "  0.26500335335731506,\n",
              "  0.2619922459125519,\n",
              "  0.2590909004211426,\n",
              "  0.2556890547275543,\n",
              "  0.25270727276802063,\n",
              "  0.24938802421092987,\n",
              "  0.2465173751115799,\n",
              "  0.2437961846590042,\n",
              "  0.24182064831256866,\n",
              "  0.23926617205142975,\n",
              "  0.23659054934978485,\n",
              "  0.23422685265541077,\n",
              "  0.2316911369562149,\n",
              "  0.22988557815551758,\n",
              "  0.22714272141456604,\n",
              "  0.22394625842571259,\n",
              "  0.22160521149635315,\n",
              "  0.21935755014419556,\n",
              "  0.2170420140028,\n",
              "  0.21475791931152344,\n",
              "  0.21250088512897491,\n",
              "  0.21102043986320496,\n",
              "  0.20852473378181458,\n",
              "  0.20565995573997498,\n",
              "  0.20429810881614685,\n",
              "  0.20161865651607513,\n",
              "  0.19976122677326202,\n",
              "  0.197660893201828,\n",
              "  0.1951839029788971,\n",
              "  0.193744495511055,\n",
              "  0.19176886975765228,\n",
              "  0.19047604501247406,\n",
              "  0.1881597340106964,\n",
              "  0.18657270073890686,\n",
              "  0.18546585738658905,\n",
              "  0.18333810567855835,\n",
              "  0.18132002651691437,\n",
              "  0.1803784966468811,\n",
              "  0.1789781004190445,\n",
              "  0.17667974531650543,\n",
              "  0.17508625984191895,\n",
              "  0.17402857542037964,\n",
              "  0.172505721449852,\n",
              "  0.17019501328468323,\n",
              "  0.16790036857128143,\n",
              "  0.1679096519947052,\n",
              "  0.16631044447422028,\n",
              "  0.1652737557888031,\n",
              "  0.16288931667804718,\n",
              "  0.16193173825740814,\n",
              "  0.16160109639167786,\n",
              "  0.15993858873844147,\n",
              "  0.1582431197166443,\n",
              "  0.15652130544185638,\n",
              "  0.15549121797084808,\n",
              "  0.15388549864292145,\n",
              "  0.15273258090019226,\n",
              "  0.15130844712257385,\n",
              "  0.15061934292316437,\n",
              "  0.15039870142936707,\n",
              "  0.14938074350357056,\n",
              "  0.1480262130498886,\n",
              "  0.14699052274227142,\n",
              "  0.1461276412010193,\n",
              "  0.144612655043602,\n",
              "  0.14322532713413239,\n",
              "  0.14310796558856964,\n",
              "  0.14178861677646637,\n",
              "  0.14027652144432068,\n",
              "  0.1393638253211975,\n",
              "  0.13910481333732605,\n",
              "  0.1375381201505661,\n",
              "  0.136965811252594,\n",
              "  0.13599228858947754,\n",
              "  0.1361643671989441,\n",
              "  0.13434775173664093,\n",
              "  0.1337619125843048,\n",
              "  0.13337568938732147,\n",
              "  0.13240568339824677,\n",
              "  0.1312689483165741,\n",
              "  0.13012398779392242,\n",
              "  0.12925750017166138,\n",
              "  0.12926097214221954,\n",
              "  0.1293065994977951,\n",
              "  0.12774544954299927,\n",
              "  0.12767738103866577,\n",
              "  0.1269604116678238,\n",
              "  0.1264086663722992,\n",
              "  0.12559466063976288,\n",
              "  0.12561629712581635,\n",
              "  0.12453199923038483,\n",
              "  0.12259653210639954,\n",
              "  0.12266241759061813,\n",
              "  0.12235555797815323,\n",
              "  0.12151510268449783,\n",
              "  0.1214263066649437,\n",
              "  0.12114062905311584,\n",
              "  0.11996494233608246,\n",
              "  0.11951331794261932,\n",
              "  0.11909656226634979,\n",
              "  0.11914069205522537,\n",
              "  0.11793734133243561,\n",
              "  0.11749598383903503,\n",
              "  0.11640094220638275,\n",
              "  0.11672724783420563,\n",
              "  0.11616262793540955]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CH-KdLkaCyVg",
        "outputId": "b3b3d030-4c49-4bb0-b337-26d5aa01bca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "epochs = range(1,501)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GJxJCu21Miw",
        "outputId": "0195f39c-7716-4014-9b7c-49302151df96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "acc_train = history.history['accuracy']\n",
        "acc_val = history.history['val_accuracy']\n",
        "epochs = range(1,501)\n",
        "plt.plot(epochs, acc_train, 'g', label='Training accuracy')\n",
        "plt.plot(epochs, acc_val, 'b', label='validation accuracy')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}